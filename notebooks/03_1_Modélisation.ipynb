{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8784e145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# IMPORTS\n",
    "# ============================================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import pickle\n",
    "from collections import Counter\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Gestion du déséquilibre\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "# Modèles\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Métriques\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, \n",
    "    f1_score, roc_auc_score, confusion_matrix,\n",
    "    classification_report\n",
    ")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f13ba59",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# 1. IMPORTATION DE LA BASE\n",
    "# ============================================================================\n",
    "def load_data(filepath):\n",
    "    \"\"\"Charge les données depuis un fichier CSV.\"\"\"\n",
    "    print(\"Chargement des données...\")\n",
    "    df = pd.read_csv(filepath)\n",
    "    print(f\"Dimensions : {df.shape}\")\n",
    "    print(f\"Valeurs manquantes : {df.isnull().sum().sum()}\")\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f094bc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# 2. SPLIT TRAIN/TEST\n",
    "# ============================================================================\n",
    "def split_data(df, target_column, test_size=0.2, random_state=42):\n",
    "    \"\"\"Sépare les données en ensembles d'entraînement et de test.\"\"\"\n",
    "    print(\"\\nSéparation des données...\")\n",
    "    \n",
    "    X = df.drop(columns=[target_column])\n",
    "    y = df[target_column]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=random_state, stratify=y\n",
    "    )\n",
    "    \n",
    "    print(f\"Train : {X_train.shape[0]} échantillons\")\n",
    "    print(f\"Test : {X_test.shape[0]} échantillons\")\n",
    "    print(f\"Distribution train : {Counter(y_train)}\")\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f61972b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# ============================================================================\n",
    "# 3. GESTION DES VALEURS MANQUANTES\n",
    "# ============================================================================\n",
    "\n",
    "# 3.1 Fonction d'imputation\n",
    "def impute_missing_values(X_train, X_test, method=\"median\"):\n",
    "    \"\"\"\n",
    "    Impute les valeurs manquantes.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    method : str\n",
    "        \"median\", \"mean\", \"knn\"\n",
    "    \"\"\"\n",
    "    print(f\"\\nImputation avec méthode : {method}\")\n",
    "    \n",
    "    X_train = X_train.copy()\n",
    "    X_test = X_test.copy()\n",
    "    \n",
    "    # Conversion des booléens\n",
    "    bool_cols = X_train.select_dtypes(include=[\"bool\"]).columns\n",
    "    X_train[bool_cols] = X_train[bool_cols].astype(int)\n",
    "    X_test[bool_cols] = X_test[bool_cols].astype(int)\n",
    "    \n",
    "    # Détection des types\n",
    "    num_cols = X_train.select_dtypes(include=[\"int64\", \"float64\"]).columns\n",
    "    cat_cols = X_train.select_dtypes(include=[\"object\"]).columns\n",
    "    \n",
    "    # Imputers\n",
    "    if method == \"knn\":\n",
    "        num_imputer = KNNImputer(n_neighbors=5)\n",
    "    elif method == \"mean\":\n",
    "        num_imputer = SimpleImputer(strategy=\"mean\")\n",
    "    else:\n",
    "        num_imputer = SimpleImputer(strategy=\"median\")\n",
    "    \n",
    "    cat_imputer = SimpleImputer(strategy=\"most_frequent\")\n",
    "    \n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", num_imputer, num_cols),\n",
    "            (\"cat\", cat_imputer, cat_cols)\n",
    "        ],\n",
    "        remainder=\"drop\"\n",
    "    )\n",
    "    \n",
    "    X_train_clean = preprocessor.fit_transform(X_train)\n",
    "    X_test_clean = preprocessor.transform(X_test)\n",
    "    \n",
    "    print(f\"Shape après imputation - Train: {X_train_clean.shape}, Test: {X_test_clean.shape}\")\n",
    "    \n",
    "    return X_train_clean, X_test_clean\n",
    "\n",
    "\n",
    "# 3.2 Fonction de suppression\n",
    "def drop_missing_values(X_train, X_test, y_train, y_test):\n",
    "    \"\"\"Supprime les lignes contenant des valeurs manquantes.\"\"\"\n",
    "    print(\"\\nSuppression des valeurs manquantes...\")\n",
    "    \n",
    "    X_train = X_train.copy()\n",
    "    X_test = X_test.copy()\n",
    "    \n",
    "    # Train\n",
    "    mask_train = ~X_train.isna().any(axis=1)\n",
    "    X_train_clean = X_train[mask_train].reset_index(drop=True)\n",
    "    y_train_clean = y_train[mask_train].reset_index(drop=True)\n",
    "    \n",
    "    # Test\n",
    "    mask_test = ~X_test.isna().any(axis=1)\n",
    "    X_test_clean = X_test[mask_test].reset_index(drop=True)\n",
    "    y_test_clean = y_test[mask_test].reset_index(drop=True)\n",
    "    \n",
    "    print(f\"Train : {len(X_train)} → {len(X_train_clean)} ({len(X_train) - len(X_train_clean)} supprimés)\")\n",
    "    print(f\"Test : {len(X_test)} → {len(X_test_clean)} ({len(X_test) - len(X_test_clean)} supprimés)\")\n",
    "    \n",
    "    return X_train_clean, X_test_clean, y_train_clean, y_test_clean\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "062e1f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# 4. GESTION DES DÉSÉQUILIBRES\n",
    "# ============================================================================\n",
    "def handle_imbalance(X_train, y_train, method=\"none\"):\n",
    "    \"\"\"\n",
    "    Gère le déséquilibre des classes.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    method : str\n",
    "        \"none\", \"weight\", \"smote\", \"smote_tomek\"\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- Gestion du déséquilibre : {method.upper()} ---\")\n",
    "    print(f\"Distribution avant : {Counter(y_train)}\")\n",
    "    \n",
    "    if method == \"none\":\n",
    "        return X_train, y_train, None\n",
    "    \n",
    "    elif method == \"weight\":\n",
    "        n_samples = len(y_train)\n",
    "        n_classes = len(np.unique(y_train))\n",
    "        class_weight = {\n",
    "            cls: n_samples / (n_classes * count) \n",
    "            for cls, count in Counter(y_train).items()\n",
    "        }\n",
    "        print(f\"Poids calculés : {class_weight}\")\n",
    "        return X_train, y_train, class_weight\n",
    "    \n",
    "    elif method == \"smote\":\n",
    "        smote = SMOTE(random_state=42, k_neighbors=5)\n",
    "        X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "        print(f\"Distribution après SMOTE : {Counter(y_resampled)}\")\n",
    "        return X_resampled, y_resampled, None\n",
    "    \n",
    "    elif method == \"smote_tomek\":\n",
    "        smote_tomek = SMOTETomek(random_state=42)\n",
    "        X_resampled, y_resampled = smote_tomek.fit_resample(X_train, y_train)\n",
    "        print(f\"Distribution après SMOTE+Tomek : {Counter(y_resampled)}\")\n",
    "        return X_resampled, y_resampled, None\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f\"Méthode inconnue : {method}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9fc5264f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# 5. CONFIGURATION DES MODÈLES\n",
    "# ============================================================================\n",
    "def get_models(class_weight=None, scale_pos_weight=1):\n",
    "    \"\"\"Retourne les trois modèles configurés.\"\"\"\n",
    "    \n",
    "    models = {\n",
    "        'KNN': KNeighborsClassifier(\n",
    "            n_neighbors=5,\n",
    "            metric='minkowski',\n",
    "            p=2\n",
    "        ),\n",
    "        'Random_Forest': RandomForestClassifier(\n",
    "            n_estimators=100,\n",
    "            random_state=42,\n",
    "            class_weight=class_weight,\n",
    "            max_depth=None,\n",
    "            min_samples_split=2\n",
    "        ),\n",
    "        'XGBoost': XGBClassifier(\n",
    "            random_state=42,\n",
    "            scale_pos_weight=scale_pos_weight,\n",
    "            use_label_encoder=False,\n",
    "            eval_metric='logloss',\n",
    "            n_estimators=100,\n",
    "            learning_rate=0.1\n",
    "        )\n",
    "    }\n",
    "    \n",
    "    return models\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "218ef6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# 6. ENTRAÎNEMENT\n",
    "# ============================================================================\n",
    "def train_models(models, X_train, y_train):\n",
    "    \"\"\"Entraîne tous les modèles.\"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"ENTRAÎNEMENT DES MODÈLES\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    trained_models = {}\n",
    "    \n",
    "    for model_name, model in models.items():\n",
    "        print(f\"\\n{model_name}...\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        elapsed_time = time.time() - start_time\n",
    "        trained_models[model_name] = {\n",
    "            'model': model,\n",
    "            'training_time': elapsed_time\n",
    "        }\n",
    "        \n",
    "        print(f\"Temps d'entraînement : {elapsed_time:.2f}s\")\n",
    "    \n",
    "    return trained_models\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2bcc5fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# 7. ÉVALUATION\n",
    "# ============================================================================\n",
    "def evaluate_models(trained_models, X_train, y_train, X_test, y_test):\n",
    "    \"\"\"Évalue les modèles sur train et test.\"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"ÉVALUATION DES MODÈLES\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for model_name, model_info in trained_models.items():\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"{model_name}\")\n",
    "        print(f\"{'='*70}\")\n",
    "        \n",
    "        model = model_info['model']\n",
    "        \n",
    "        # Prédictions\n",
    "        y_train_pred = model.predict(X_train)\n",
    "        y_test_pred = model.predict(X_test)\n",
    "        \n",
    "        y_train_proba = model.predict_proba(X_train)[:, 1]\n",
    "        y_test_proba = model.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "        # Métriques Train\n",
    "        train_metrics = {\n",
    "            'accuracy': accuracy_score(y_train, y_train_pred),\n",
    "            'precision': precision_score(y_train, y_train_pred),\n",
    "            'recall': recall_score(y_train, y_train_pred),\n",
    "            'f1': f1_score(y_train, y_train_pred),\n",
    "            'auc': roc_auc_score(y_train, y_train_proba)\n",
    "        }\n",
    "        \n",
    "        # Métriques Test\n",
    "        test_metrics = {\n",
    "            'accuracy': accuracy_score(y_test, y_test_pred),\n",
    "            'precision': precision_score(y_test, y_test_pred),\n",
    "            'recall': recall_score(y_test, y_test_pred),\n",
    "            'f1': f1_score(y_test, y_test_pred),\n",
    "            'auc': roc_auc_score(y_test, y_test_proba)\n",
    "        }\n",
    "        \n",
    "        # Affichage\n",
    "        print(\"\\nTRAIN:\")\n",
    "        for metric, value in train_metrics.items():\n",
    "            print(f\"  {metric.upper():12} : {value:.4f}\")\n",
    "        \n",
    "        print(\"\\nTEST:\")\n",
    "        for metric, value in test_metrics.items():\n",
    "            print(f\"  {metric.upper():12} : {value:.4f}\")\n",
    "        \n",
    "        print(\"\\nMatrice de confusion (Test):\")\n",
    "        print(confusion_matrix(y_test, y_test_pred))\n",
    "        \n",
    "        # Stockage\n",
    "        results[model_name] = {\n",
    "            'train_metrics': train_metrics,\n",
    "            'test_metrics': test_metrics,\n",
    "            'confusion_matrix': confusion_matrix(y_test, y_test_pred),\n",
    "            'training_time': model_info['training_time']\n",
    "        }\n",
    "    \n",
    "    return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2a1890a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 8. SAUVEGARDE DES MODÈLES ET RÉSULTATS\n",
    "# ============================================================================\n",
    "import os\n",
    "import json\n",
    "\n",
    "def save_models(trained_models, results, prefix=\"model\"):\n",
    "    \"\"\"\n",
    "    Sauvegarde les modèles et leurs résultats dans des dossiers séparés.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    trained_models : dict\n",
    "        Dictionnaire contenant les modèles entraînés\n",
    "    results : dict\n",
    "        Dictionnaire contenant les résultats d'évaluation\n",
    "    prefix : str\n",
    "        Préfixe pour les noms de fichiers\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"SAUVEGARDE DES MODÈLES ET RÉSULTATS\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Créer les dossiers s'ils n'existent pas\n",
    "    models_dir = \"../models\"\n",
    "    results_dir = \"../results\"\n",
    "    \n",
    "    os.makedirs(models_dir, exist_ok=True)\n",
    "    os.makedirs(results_dir, exist_ok=True)\n",
    "    \n",
    "    print(f\"\\nDossier modèles : {models_dir}\")\n",
    "    print(f\"Dossier résultats : {results_dir}\")\n",
    "    \n",
    "    for model_name, model_info in trained_models.items():\n",
    "        # Nom des fichiers\n",
    "        model_filename = os.path.join(models_dir, f\"{prefix}_{model_name}.pkl\")\n",
    "        results_filename = os.path.join(results_dir, f\"{prefix}_{model_name}_results.json\")\n",
    "        \n",
    "        # Sauvegarde du modèle\n",
    "        with open(model_filename, 'wb') as f:\n",
    "            pickle.dump(model_info['model'], f)\n",
    "        print(f\"✓ Modèle sauvegardé : {model_filename}\")\n",
    "        \n",
    "        # Préparation des résultats pour JSON\n",
    "        results_to_save = {\n",
    "            'train_metrics': results[model_name]['train_metrics'],\n",
    "            'test_metrics': results[model_name]['test_metrics'],\n",
    "            'confusion_matrix': results[model_name]['confusion_matrix'].tolist(),\n",
    "            'training_time': results[model_name]['training_time']\n",
    "        }\n",
    "        \n",
    "        # Sauvegarde des résultats\n",
    "        with open(results_filename, 'w') as f:\n",
    "            json.dump(results_to_save, f, indent=4)\n",
    "        print(f\"✓ Résultats sauvegardés : {results_filename}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"Tous les modèles et résultats ont été sauvegardés.\")\n",
    "    print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06781769",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# 9. PIPELINE COMPLET\n",
    "# ============================================================================\n",
    "def run_pipeline(filepath, target_column, \n",
    "                 missing_method=\"impute\", impute_strategy=\"median\",\n",
    "                 balance_method=\"smote\", \n",
    "                 save_prefix=\"model\"):\n",
    "    \"\"\"\n",
    "    Exécute le pipeline complet de modélisation.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    filepath : str\n",
    "        Chemin vers le fichier CSV\n",
    "    target_column : str\n",
    "        Nom de la colonne cible\n",
    "    missing_method : str\n",
    "        \"impute\" ou \"drop\"\n",
    "    impute_strategy : str\n",
    "        \"median\", \"mean\", \"knn\" (si missing_method=\"impute\")\n",
    "    balance_method : str\n",
    "        \"none\", \"weight\", \"smote\", \"smote_tomek\"\n",
    "    save_prefix : str\n",
    "        Préfixe pour les fichiers sauvegardés\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"PIPELINE DE MODÉLISATION\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"Fichier : {filepath}\")\n",
    "    print(f\"Gestion des manquantes : {missing_method}\")\n",
    "    if missing_method == \"impute\":\n",
    "        print(f\"Stratégie d'imputation : {impute_strategy}\")\n",
    "    print(f\"Gestion du déséquilibre : {balance_method}\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # 1. Chargement\n",
    "    df = load_data(filepath)\n",
    "    \n",
    "    # 2. Split\n",
    "    X_train, X_test, y_train, y_test = split_data(df, target_column)\n",
    "    \n",
    "    # 3. Gestion des valeurs manquantes\n",
    "    if missing_method == \"impute\":\n",
    "        X_train_clean, X_test_clean = impute_missing_values(\n",
    "            X_train, X_test, method=impute_strategy\n",
    "        )\n",
    "        y_train_clean = y_train\n",
    "        y_test_clean = y_test\n",
    "    elif missing_method == \"drop\":\n",
    "        X_train_clean, X_test_clean, y_train_clean, y_test_clean = drop_missing_values(\n",
    "            X_train, X_test, y_train, y_test\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(f\"missing_method inconnu : {missing_method}\")\n",
    "    \n",
    "    # 4. Gestion du déséquilibre\n",
    "    X_train_balanced, y_train_balanced, class_weight = handle_imbalance(\n",
    "        X_train_clean, y_train_clean, method=balance_method\n",
    "    )\n",
    "    \n",
    "    # Calcul du scale_pos_weight pour XGBoost\n",
    "    if balance_method in [\"none\", \"weight\"]:\n",
    "        ratio = Counter(y_train_clean)[0] / Counter(y_train_clean)[1]\n",
    "    else:\n",
    "        ratio = 1\n",
    "    \n",
    "    # 5. Configuration des modèles\n",
    "    if balance_method == \"weight\":\n",
    "        models = get_models(class_weight=class_weight, scale_pos_weight=ratio)\n",
    "    elif balance_method in [\"smote\", \"smote_tomek\"]:\n",
    "        models = get_models(class_weight=None, scale_pos_weight=1)\n",
    "    else:\n",
    "        models = get_models(class_weight=None, scale_pos_weight=ratio)\n",
    "    \n",
    "    # 6. Entraînement\n",
    "    trained_models = train_models(models, X_train_balanced, y_train_balanced)\n",
    "    \n",
    "    # 7. Évaluation\n",
    "    results = evaluate_models(\n",
    "        trained_models, \n",
    "        X_train_balanced, y_train_balanced,\n",
    "        X_test_clean, y_test_clean\n",
    "    )\n",
    "    \n",
    "    # 8. Sauvegarde\n",
    "    save_models(trained_models, results, prefix=save_prefix)\n",
    "    \n",
    "    return trained_models, results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7496905a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "######################################################################\n",
      "# SCÉNARIO : Imputation_Median_SMOTE\n",
      "######################################################################\n",
      "\n",
      "======================================================================\n",
      "PIPELINE DE MODÉLISATION\n",
      "======================================================================\n",
      "Fichier : ../data/df_dropna_normalized.csv\n",
      "Gestion des manquantes : impute\n",
      "Stratégie d'imputation : median\n",
      "Gestion du déséquilibre : smote\n",
      "======================================================================\n",
      "Chargement des données...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions : (19021, 39)\n",
      "Valeurs manquantes : 2\n",
      "\n",
      "Séparation des données...\n",
      "Train : 15216 échantillons\n",
      "Test : 3805 échantillons\n",
      "Distribution train : Counter({0: 13473, 1: 1743})\n",
      "\n",
      "Imputation avec méthode : median\n",
      "Shape après imputation - Train: (15216, 32), Test: (3805, 32)\n",
      "\n",
      "--- Gestion du déséquilibre : SMOTE ---\n",
      "Distribution avant : Counter({0: 13473, 1: 1743})\n",
      "Distribution après SMOTE : Counter({0: 13473, 1: 13473})\n",
      "\n",
      "======================================================================\n",
      "ENTRAÎNEMENT DES MODÈLES\n",
      "======================================================================\n",
      "\n",
      "KNN...\n",
      "Temps d'entraînement : 0.01s\n",
      "\n",
      "Random_Forest...\n",
      "Temps d'entraînement : 22.11s\n",
      "\n",
      "XGBoost...\n",
      "Temps d'entraînement : 2.20s\n",
      "\n",
      "======================================================================\n",
      "ÉVALUATION DES MODÈLES\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "KNN\n",
      "======================================================================\n",
      "\n",
      "TRAIN:\n",
      "  ACCURACY     : 0.8732\n",
      "  PRECISION    : 0.8091\n",
      "  RECALL       : 0.9769\n",
      "  F1           : 0.8851\n",
      "  AUC          : 0.9733\n",
      "\n",
      "TEST:\n",
      "  ACCURACY     : 0.6668\n",
      "  PRECISION    : 0.1573\n",
      "  RECALL       : 0.4381\n",
      "  F1           : 0.2315\n",
      "  AUC          : 0.5840\n",
      "\n",
      "Matrice de confusion (Test):\n",
      "[[2346 1023]\n",
      " [ 245  191]]\n",
      "\n",
      "======================================================================\n",
      "Random_Forest\n",
      "======================================================================\n",
      "\n",
      "TRAIN:\n",
      "  ACCURACY     : 1.0000\n",
      "  PRECISION    : 1.0000\n",
      "  RECALL       : 1.0000\n",
      "  F1           : 1.0000\n",
      "  AUC          : 1.0000\n",
      "\n",
      "TEST:\n",
      "  ACCURACY     : 0.8880\n",
      "  PRECISION    : 0.7083\n",
      "  RECALL       : 0.0390\n",
      "  F1           : 0.0739\n",
      "  AUC          : 0.7515\n",
      "\n",
      "Matrice de confusion (Test):\n",
      "[[3362    7]\n",
      " [ 419   17]]\n",
      "\n",
      "======================================================================\n",
      "XGBoost\n",
      "======================================================================\n",
      "\n",
      "TRAIN:\n",
      "  ACCURACY     : 0.9440\n",
      "  PRECISION    : 0.9979\n",
      "  RECALL       : 0.8899\n",
      "  F1           : 0.9408\n",
      "  AUC          : 0.9855\n",
      "\n",
      "TEST:\n",
      "  ACCURACY     : 0.8922\n",
      "  PRECISION    : 0.8250\n",
      "  RECALL       : 0.0757\n",
      "  F1           : 0.1387\n",
      "  AUC          : 0.7779\n",
      "\n",
      "Matrice de confusion (Test):\n",
      "[[3362    7]\n",
      " [ 403   33]]\n",
      "\n",
      "======================================================================\n",
      "SAUVEGARDE DES MODÈLES ET RÉSULTATS\n",
      "======================================================================\n",
      "\n",
      "Dossier modèles : ../models\n",
      "Dossier résultats : ../results\n",
      "✓ Modèle sauvegardé : ../models\\Imputation_Median_SMOTE_KNN.pkl\n",
      "✓ Résultats sauvegardés : ../results\\Imputation_Median_SMOTE_KNN_results.json\n",
      "✓ Modèle sauvegardé : ../models\\Imputation_Median_SMOTE_Random_Forest.pkl\n",
      "✓ Résultats sauvegardés : ../results\\Imputation_Median_SMOTE_Random_Forest_results.json\n",
      "✓ Modèle sauvegardé : ../models\\Imputation_Median_SMOTE_XGBoost.pkl\n",
      "✓ Résultats sauvegardés : ../results\\Imputation_Median_SMOTE_XGBoost_results.json\n",
      "\n",
      "======================================================================\n",
      "Tous les modèles et résultats ont été sauvegardés.\n",
      "======================================================================\n",
      "\n",
      "\n",
      "######################################################################\n",
      "# SCÉNARIO : Imputation_KNN_SMOTE\n",
      "######################################################################\n",
      "\n",
      "======================================================================\n",
      "PIPELINE DE MODÉLISATION\n",
      "======================================================================\n",
      "Fichier : ../data/df_dropna_normalized.csv\n",
      "Gestion des manquantes : impute\n",
      "Stratégie d'imputation : knn\n",
      "Gestion du déséquilibre : smote\n",
      "======================================================================\n",
      "Chargement des données...\n",
      "Dimensions : (19021, 39)\n",
      "Valeurs manquantes : 2\n",
      "\n",
      "Séparation des données...\n",
      "Train : 15216 échantillons\n",
      "Test : 3805 échantillons\n",
      "Distribution train : Counter({0: 13473, 1: 1743})\n",
      "\n",
      "Imputation avec méthode : knn\n",
      "Shape après imputation - Train: (15216, 32), Test: (3805, 32)\n",
      "\n",
      "--- Gestion du déséquilibre : SMOTE ---\n",
      "Distribution avant : Counter({0: 13473, 1: 1743})\n",
      "Distribution après SMOTE : Counter({0: 13473, 1: 13473})\n",
      "\n",
      "======================================================================\n",
      "ENTRAÎNEMENT DES MODÈLES\n",
      "======================================================================\n",
      "\n",
      "KNN...\n",
      "Temps d'entraînement : 0.00s\n",
      "\n",
      "Random_Forest...\n",
      "Temps d'entraînement : 12.74s\n",
      "\n",
      "XGBoost...\n",
      "Temps d'entraînement : 0.96s\n",
      "\n",
      "======================================================================\n",
      "ÉVALUATION DES MODÈLES\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "KNN\n",
      "======================================================================\n",
      "\n",
      "TRAIN:\n",
      "  ACCURACY     : 0.8732\n",
      "  PRECISION    : 0.8091\n",
      "  RECALL       : 0.9769\n",
      "  F1           : 0.8851\n",
      "  AUC          : 0.9733\n",
      "\n",
      "TEST:\n",
      "  ACCURACY     : 0.6668\n",
      "  PRECISION    : 0.1573\n",
      "  RECALL       : 0.4381\n",
      "  F1           : 0.2315\n",
      "  AUC          : 0.5840\n",
      "\n",
      "Matrice de confusion (Test):\n",
      "[[2346 1023]\n",
      " [ 245  191]]\n",
      "\n",
      "======================================================================\n",
      "Random_Forest\n",
      "======================================================================\n",
      "\n",
      "TRAIN:\n",
      "  ACCURACY     : 1.0000\n",
      "  PRECISION    : 1.0000\n",
      "  RECALL       : 1.0000\n",
      "  F1           : 1.0000\n",
      "  AUC          : 1.0000\n",
      "\n",
      "TEST:\n",
      "  ACCURACY     : 0.8883\n",
      "  PRECISION    : 0.7619\n",
      "  RECALL       : 0.0367\n",
      "  F1           : 0.0700\n",
      "  AUC          : 0.7505\n",
      "\n",
      "Matrice de confusion (Test):\n",
      "[[3364    5]\n",
      " [ 420   16]]\n",
      "\n",
      "======================================================================\n",
      "XGBoost\n",
      "======================================================================\n",
      "\n",
      "TRAIN:\n",
      "  ACCURACY     : 0.9442\n",
      "  PRECISION    : 0.9980\n",
      "  RECALL       : 0.8902\n",
      "  F1           : 0.9410\n",
      "  AUC          : 0.9856\n",
      "\n",
      "TEST:\n",
      "  ACCURACY     : 0.8915\n",
      "  PRECISION    : 0.7674\n",
      "  RECALL       : 0.0757\n",
      "  F1           : 0.1378\n",
      "  AUC          : 0.7831\n",
      "\n",
      "Matrice de confusion (Test):\n",
      "[[3359   10]\n",
      " [ 403   33]]\n",
      "\n",
      "======================================================================\n",
      "SAUVEGARDE DES MODÈLES ET RÉSULTATS\n",
      "======================================================================\n",
      "\n",
      "Dossier modèles : ../models\n",
      "Dossier résultats : ../results\n",
      "✓ Modèle sauvegardé : ../models\\Imputation_KNN_SMOTE_KNN.pkl\n",
      "✓ Résultats sauvegardés : ../results\\Imputation_KNN_SMOTE_KNN_results.json\n",
      "✓ Modèle sauvegardé : ../models\\Imputation_KNN_SMOTE_Random_Forest.pkl\n",
      "✓ Résultats sauvegardés : ../results\\Imputation_KNN_SMOTE_Random_Forest_results.json\n",
      "✓ Modèle sauvegardé : ../models\\Imputation_KNN_SMOTE_XGBoost.pkl\n",
      "✓ Résultats sauvegardés : ../results\\Imputation_KNN_SMOTE_XGBoost_results.json\n",
      "\n",
      "======================================================================\n",
      "Tous les modèles et résultats ont été sauvegardés.\n",
      "======================================================================\n",
      "\n",
      "\n",
      "######################################################################\n",
      "# SCÉNARIO : Drop_SMOTE\n",
      "######################################################################\n",
      "\n",
      "======================================================================\n",
      "PIPELINE DE MODÉLISATION\n",
      "======================================================================\n",
      "Fichier : ../data/df_dropna_normalized.csv\n",
      "Gestion des manquantes : drop\n",
      "Gestion du déséquilibre : smote\n",
      "======================================================================\n",
      "Chargement des données...\n",
      "Dimensions : (19021, 39)\n",
      "Valeurs manquantes : 2\n",
      "\n",
      "Séparation des données...\n",
      "Train : 15216 échantillons\n",
      "Test : 3805 échantillons\n",
      "Distribution train : Counter({0: 13473, 1: 1743})\n",
      "\n",
      "Suppression des valeurs manquantes...\n",
      "Train : 15216 → 15214 (2 supprimés)\n",
      "Test : 3805 → 3805 (0 supprimés)\n",
      "\n",
      "--- Gestion du déséquilibre : SMOTE ---\n",
      "Distribution avant : Counter({0: 13471, 1: 1743})\n",
      "Distribution après SMOTE : Counter({0: 13471, 1: 13471})\n",
      "\n",
      "======================================================================\n",
      "ENTRAÎNEMENT DES MODÈLES\n",
      "======================================================================\n",
      "\n",
      "KNN...\n",
      "Temps d'entraînement : 0.03s\n",
      "\n",
      "Random_Forest...\n",
      "Temps d'entraînement : 13.30s\n",
      "\n",
      "XGBoost...\n",
      "Temps d'entraînement : 0.79s\n",
      "\n",
      "======================================================================\n",
      "ÉVALUATION DES MODÈLES\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "KNN\n",
      "======================================================================\n",
      "\n",
      "TRAIN:\n",
      "  ACCURACY     : 0.8734\n",
      "  PRECISION    : 0.8086\n",
      "  RECALL       : 0.9784\n",
      "  F1           : 0.8854\n",
      "  AUC          : 0.9739\n",
      "\n",
      "TEST:\n",
      "  ACCURACY     : 0.6660\n",
      "  PRECISION    : 0.1592\n",
      "  RECALL       : 0.4472\n",
      "  F1           : 0.2348\n",
      "  AUC          : 0.5854\n",
      "\n",
      "Matrice de confusion (Test):\n",
      "[[2339 1030]\n",
      " [ 241  195]]\n",
      "\n",
      "======================================================================\n",
      "Random_Forest\n",
      "======================================================================\n",
      "\n",
      "TRAIN:\n",
      "  ACCURACY     : 1.0000\n",
      "  PRECISION    : 1.0000\n",
      "  RECALL       : 1.0000\n",
      "  F1           : 1.0000\n",
      "  AUC          : 1.0000\n",
      "\n",
      "TEST:\n",
      "  ACCURACY     : 0.8920\n",
      "  PRECISION    : 0.8378\n",
      "  RECALL       : 0.0711\n",
      "  F1           : 0.1311\n",
      "  AUC          : 0.8042\n",
      "\n",
      "Matrice de confusion (Test):\n",
      "[[3363    6]\n",
      " [ 405   31]]\n",
      "\n",
      "======================================================================\n",
      "XGBoost\n",
      "======================================================================\n",
      "\n",
      "TRAIN:\n",
      "  ACCURACY     : 0.9565\n",
      "  PRECISION    : 0.9971\n",
      "  RECALL       : 0.9157\n",
      "  F1           : 0.9547\n",
      "  AUC          : 0.9914\n",
      "\n",
      "TEST:\n",
      "  ACCURACY     : 0.9062\n",
      "  PRECISION    : 0.8160\n",
      "  RECALL       : 0.2339\n",
      "  F1           : 0.3636\n",
      "  AUC          : 0.8687\n",
      "\n",
      "Matrice de confusion (Test):\n",
      "[[3346   23]\n",
      " [ 334  102]]\n",
      "\n",
      "======================================================================\n",
      "SAUVEGARDE DES MODÈLES ET RÉSULTATS\n",
      "======================================================================\n",
      "\n",
      "Dossier modèles : ../models\n",
      "Dossier résultats : ../results\n",
      "✓ Modèle sauvegardé : ../models\\Drop_SMOTE_KNN.pkl\n",
      "✓ Résultats sauvegardés : ../results\\Drop_SMOTE_KNN_results.json\n",
      "✓ Modèle sauvegardé : ../models\\Drop_SMOTE_Random_Forest.pkl\n",
      "✓ Résultats sauvegardés : ../results\\Drop_SMOTE_Random_Forest_results.json\n",
      "✓ Modèle sauvegardé : ../models\\Drop_SMOTE_XGBoost.pkl\n",
      "✓ Résultats sauvegardés : ../results\\Drop_SMOTE_XGBoost_results.json\n",
      "\n",
      "======================================================================\n",
      "Tous les modèles et résultats ont été sauvegardés.\n",
      "======================================================================\n",
      "\n",
      "\n",
      "######################################################################\n",
      "# SCÉNARIO : Imputation_Median_SMOTETomek\n",
      "######################################################################\n",
      "\n",
      "======================================================================\n",
      "PIPELINE DE MODÉLISATION\n",
      "======================================================================\n",
      "Fichier : ../data/df_dropna_normalized.csv\n",
      "Gestion des manquantes : impute\n",
      "Stratégie d'imputation : median\n",
      "Gestion du déséquilibre : smote_tomek\n",
      "======================================================================\n",
      "Chargement des données...\n",
      "Dimensions : (19021, 39)\n",
      "Valeurs manquantes : 2\n",
      "\n",
      "Séparation des données...\n",
      "Train : 15216 échantillons\n",
      "Test : 3805 échantillons\n",
      "Distribution train : Counter({0: 13473, 1: 1743})\n",
      "\n",
      "Imputation avec méthode : median\n",
      "Shape après imputation - Train: (15216, 32), Test: (3805, 32)\n",
      "\n",
      "--- Gestion du déséquilibre : SMOTE_TOMEK ---\n",
      "Distribution avant : Counter({0: 13473, 1: 1743})\n",
      "Distribution après SMOTE+Tomek : Counter({0: 13069, 1: 13069})\n",
      "\n",
      "======================================================================\n",
      "ENTRAÎNEMENT DES MODÈLES\n",
      "======================================================================\n",
      "\n",
      "KNN...\n",
      "Temps d'entraînement : 0.01s\n",
      "\n",
      "Random_Forest...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# 10. EXÉCUTION\n",
    "# ============================================================================\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # Configuration\n",
    "    FILEPATH = \"../data/df_dropna_normalized.csv\"\n",
    "    TARGET = \"embauche\"  # Nom de votre colonne cible\n",
    "    \n",
    "    # Scénarios à tester\n",
    "    scenarios = [\n",
    "        {\n",
    "            'name': 'Imputation_Median_SMOTE',\n",
    "            'missing_method': 'impute',\n",
    "            'impute_strategy': 'median',\n",
    "            'balance_method': 'smote'\n",
    "        },\n",
    "        {\n",
    "            'name': 'Imputation_KNN_SMOTE',\n",
    "            'missing_method': 'impute',\n",
    "            'impute_strategy': 'knn',\n",
    "            'balance_method': 'smote'\n",
    "        },\n",
    "        {\n",
    "            'name': 'Drop_SMOTE',\n",
    "            'missing_method': 'drop',\n",
    "            'impute_strategy': None,\n",
    "            'balance_method': 'smote'\n",
    "        },\n",
    "        {\n",
    "            'name': 'Imputation_Median_SMOTETomek',\n",
    "            'missing_method': 'impute',\n",
    "            'impute_strategy': 'median',\n",
    "            'balance_method': 'smote_tomek'\n",
    "        },\n",
    "        {\n",
    "            'name': 'Imputation_Median_Weight',\n",
    "            'missing_method': 'impute',\n",
    "            'impute_strategy': 'median',\n",
    "            'balance_method': 'weight'\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    # Exécution de tous les scénarios\n",
    "    all_results = {}\n",
    "    \n",
    "    for scenario in scenarios:\n",
    "        print(\"\\n\\n\" + \"#\"*70)\n",
    "        print(f\"# SCÉNARIO : {scenario['name']}\")\n",
    "        print(\"#\"*70)\n",
    "        \n",
    "        trained_models, results = run_pipeline(\n",
    "            filepath=FILEPATH,\n",
    "            target_column=TARGET,\n",
    "            missing_method=scenario['missing_method'],\n",
    "            impute_strategy=scenario.get('impute_strategy', 'median'),\n",
    "            balance_method=scenario['balance_method'],\n",
    "            save_prefix=scenario['name']\n",
    "        )\n",
    "        \n",
    "        all_results[scenario['name']] = results\n",
    "    \n",
    "    # Comparaison finale\n",
    "    print(\"\\n\\n\" + \"=\"*70)\n",
    "    print(\"COMPARAISON FINALE DES SCÉNARIOS\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    for scenario_name, results in all_results.items():\n",
    "        print(f\"\\n{scenario_name}:\")\n",
    "        for model_name, metrics in results.items():\n",
    "            print(f\"  {model_name:20} - Test AUC: {metrics['test_metrics']['auc']:.4f} - F1: {metrics['test_metrics']['f1']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dfd8dc5",
   "metadata": {},
   "source": [
    "**TEST DU PIPELINE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44baaac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "PIPELINE DE MODÉLISATION\n",
      "======================================================================\n",
      "Fichier : ../data/df_dropna_normalized.csv\n",
      "Gestion des manquantes : impute\n",
      "Stratégie d'imputation : knn\n",
      "Gestion du déséquilibre : weight\n",
      "======================================================================\n",
      "Chargement des données...\n",
      "Dimensions : (19021, 39)\n",
      "Valeurs manquantes : 2\n",
      "\n",
      "Séparation des données...\n",
      "Train : 15216 échantillons\n",
      "Test : 3805 échantillons\n",
      "Distribution train : Counter({0: 13473, 1: 1743})\n",
      "\n",
      "Imputation avec méthode : knn\n",
      "Shape après imputation - Train: (15216, 32), Test: (3805, 32)\n",
      "\n",
      "--- Gestion du déséquilibre : WEIGHT ---\n",
      "Distribution avant : Counter({0: 13473, 1: 1743})\n",
      "Poids calculés : {0: 0.5646849254063683, 1: 4.364888123924269}\n",
      "\n",
      "======================================================================\n",
      "ENTRAÎNEMENT DES MODÈLES\n",
      "======================================================================\n",
      "\n",
      "KNN...\n",
      "Temps d'entraînement : 0.01s\n",
      "\n",
      "Random_Forest...\n",
      "Temps d'entraînement : 6.44s\n",
      "\n",
      "XGBoost...\n",
      "Temps d'entraînement : 0.51s\n",
      "\n",
      "======================================================================\n",
      "ÉVALUATION DES MODÈLES\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "KNN\n",
      "======================================================================\n",
      "\n",
      "TRAIN:\n",
      "  ACCURACY     : 0.8928\n",
      "  PRECISION    : 0.6739\n",
      "  RECALL       : 0.1245\n",
      "  F1           : 0.2102\n",
      "  AUC          : 0.8728\n",
      "\n",
      "TEST:\n",
      "  ACCURACY     : 0.8699\n",
      "  PRECISION    : 0.1609\n",
      "  RECALL       : 0.0321\n",
      "  F1           : 0.0535\n",
      "  AUC          : 0.5781\n",
      "\n",
      "Matrice de confusion (Test):\n",
      "[[3296   73]\n",
      " [ 422   14]]\n",
      "\n",
      "======================================================================\n",
      "Random_Forest\n",
      "======================================================================\n",
      "\n",
      "TRAIN:\n",
      "  ACCURACY     : 1.0000\n",
      "  PRECISION    : 1.0000\n",
      "  RECALL       : 1.0000\n",
      "  F1           : 1.0000\n",
      "  AUC          : 1.0000\n",
      "\n",
      "TEST:\n",
      "  ACCURACY     : 0.8870\n",
      "  PRECISION    : 0.6364\n",
      "  RECALL       : 0.0321\n",
      "  F1           : 0.0611\n",
      "  AUC          : 0.7644\n",
      "\n",
      "Matrice de confusion (Test):\n",
      "[[3361    8]\n",
      " [ 422   14]]\n",
      "\n",
      "======================================================================\n",
      "XGBoost\n",
      "======================================================================\n",
      "\n",
      "TRAIN:\n",
      "  ACCURACY     : 0.8011\n",
      "  PRECISION    : 0.3561\n",
      "  RECALL       : 0.9105\n",
      "  F1           : 0.5119\n",
      "  AUC          : 0.9316\n",
      "\n",
      "TEST:\n",
      "  ACCURACY     : 0.7293\n",
      "  PRECISION    : 0.2390\n",
      "  RECALL       : 0.6239\n",
      "  F1           : 0.3456\n",
      "  AUC          : 0.7634\n",
      "\n",
      "Matrice de confusion (Test):\n",
      "[[2503  866]\n",
      " [ 164  272]]\n",
      "\n",
      "======================================================================\n",
      "SAUVEGARDE DES MODÈLES ET RÉSULTATS\n",
      "======================================================================\n",
      "\n",
      "Dossier modèles : ../models\n",
      "Dossier résultats : ../results\n",
      "✓ Modèle sauvegardé : ../models\\model_knn_weight_KNN.pkl\n",
      "✓ Résultats sauvegardés : ../results\\model_knn_weight_KNN_results.json\n",
      "✓ Modèle sauvegardé : ../models\\model_knn_weight_Random_Forest.pkl\n",
      "✓ Résultats sauvegardés : ../results\\model_knn_weight_Random_Forest_results.json\n",
      "✓ Modèle sauvegardé : ../models\\model_knn_weight_XGBoost.pkl\n",
      "✓ Résultats sauvegardés : ../results\\model_knn_weight_XGBoost_results.json\n",
      "\n",
      "======================================================================\n",
      "Tous les modèles et résultats ont été sauvegardés.\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Exécution d'un seul scénario\n",
    "trained_models, results = run_pipeline(\n",
    "    filepath=\"../data/df_dropna_normalized.csv\",\n",
    "    target_column=\"embauche\",\n",
    "    missing_method=\"impute\",      # \"impute\" ou \"drop\"\n",
    "    impute_strategy=\"knn\",     # \"median\", \"mean\", \"knn\"\n",
    "    balance_method=\"weight\",       # \"none\", \"weight\", \"smote\", \"smote_tomek\"\n",
    "    save_prefix=\"model_knn_weight\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
